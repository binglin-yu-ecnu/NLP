{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 今天是2020年1月05日，今天世界上又多了一名AI工程师 :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 作业截止时间\n",
    "此次作业截止时间为 2020.01.12日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**：每道题是否回答完整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: {Put your answer here}1、Smart city 2、Face recognition  3、Service robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: {Put your answer here}jupyter提供了一个环境，用户可以在里面写代码、运行代码、查看结果，并在其中可视化数据。鉴于这些优点，Jupyter Notebook成了数据科学家眼里的一款人见人爱的工具，它能帮助他们便捷地执行各种端到端任务，如数据清洗、统计建模、构建/训练机器学习模型等。\n",
    "PyCharm是一种Python IDE，带有一整套可以帮助用户在使用Python语言开发时提高其效率的工具，比如调试、语法高亮、Project管理、代码跳转、智能提示、自动完成、单元测试、版本控制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:统计模型[stochasticmodel；statisticmodel；probabilitymodel]指以概率论为基础，采用数学统计方法建立的模型。有些过程无法用理论分析方法导出其模型，但可通过试验测定数据，经过数理统计法求得各变量之间的函数关系，称为统计模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:1、Risk management   2、Time series analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:因为大部分时间都不是确定性事件，我们可以通过原始数据分析出某一事件发生的可能性，但并不能百分之百确定事件是否发生。困难之处在于很多语言并不是符合语法的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:语言模型是一个单词序列上的概率分布，对于一个给定长度为m的序列，它可以为整个序列产生一个概率 P(w_1,w_2,…,w_m) 。其实就是想办法找到一个概率分布，它可以表示任意一个句子或序列出现的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:1、语音识别 2、机器翻译"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:某个单词w与前后文的单词独立， unigram： $$ Pro(w_1 w_2 w_3 w_4...w_n) =\\prod_1^n Pr(w_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:没有考虑到上下文的关系，与现实不符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:一个词w在某个位置出现的概率只与它前面的一个词有关，$$ Pro(w_1 w_2 w_3 w_4...w_n) =\\prod_1^n Pr(w_i|w_{i-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1569578233461&di=4adfa7597fb380e7cc0e67190bbd7605&imgtype=0&src=http%3A%2F%2Fs1.sinaimg.cn%2Flarge%2F006eYYfyzy76cmpG3Yb1f)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在观众点播篮球比赛的一个场景里\n",
    "audience = \"\"\"\n",
    "audience = 自己 想要 动作 日期 球队 比赛\n",
    "自己 = 我 | 俺 | 我们 \n",
    "想要 = 想要 | 希望 | 想\n",
    "动作 = 观看 | 看 | 点播\n",
    "日期 = 今日 | 今天 | 现在 \n",
    "球队 = 湖人 | 凯尔特人 | 雄鹿 | 掘金 | 勇士 | 独行侠\n",
    "比赛= 篮球赛 | 比赛 | 球赛 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**： 是否提出了和课程上区别较大的语法结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentator = \"\"\"\n",
    "commentator = 介绍 球队1 球员 动作  结果 \n",
    "介绍 = 寒暄 球队 的比赛 ，\n",
    "寒暄 = 欢迎收看 | 欢迎观看 | 感谢收看 | 感谢观看\n",
    "球队 = 湖人 | 凯尔特人 | 雄鹿 | 掘金 | 勇士 | 独行侠\n",
    "球队1 = 主队 | 客队\n",
    "球员 = 中锋 | 大前锋 | 小前锋 | 得分后卫 | 控球后卫 \n",
    "动作 = 后仰跳投 | 上篮 | 三分 | 后撤步两分\n",
    "结果 = 不进 | 命中 | 稳稳命中 | 可惜不进 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**：是否和上一个语法区别比较大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_grammar(grammar_str: str,target,split='=>'):\n",
    "    grammar ={}\n",
    "                     \n",
    "    for line in grammar_str.split('\\n'):\n",
    "        if not line: continue\n",
    "            # two=>num + num\n",
    "        expression, formula = line.split(split)\n",
    "        formulas=formula.split('|')\n",
    "        formulas=[f.split() for f in formulas]\n",
    "        grammar[expression.strip()]=formulas             \n",
    "    return grammar\n",
    "choice_a_expr= random.choice\n",
    "\n",
    "def generate_by_grammar(grammar:dict, target:str):\n",
    "    if target not in grammar:return target\n",
    "    # the above line is to test if target is a key\n",
    "    expr = choice_a_expr(grammar[target])\n",
    "    return ''.join( generate_by_grammar(grammar,t) for t in expr)\n",
    "def generate_by_str(grammar_str,split,target):\n",
    "    grammar=generate_grammar(grammar_str,target,split)\n",
    "    return generate_by_grammar(grammar,target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我们想看现在掘金球赛\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    print(generate_by_str(audience, split='=',target='audience'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "感谢收看独行侠的比赛，客队大前锋后撤步两分命中\n"
     ]
    }
   ],
   "source": [
    "print(generate_by_str(commentator, split='=',target='commentator'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(grammar_str,split,target):\n",
    "    for i in range(10):\n",
    "        print(generate_by_str(grammar_str,split,target))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "感谢收看掘金的比赛，客队中锋三分可惜不进\n",
      "感谢收看凯尔特人的比赛，客队中锋后仰跳投稳稳命中\n",
      "感谢收看雄鹿的比赛，主队小前锋上篮命中\n",
      "欢迎收看独行侠的比赛，客队中锋三分命中\n",
      "欢迎收看凯尔特人的比赛，主队大前锋后仰跳投稳稳命中\n",
      "欢迎观看湖人的比赛，客队中锋三分命中\n",
      "欢迎观看雄鹿的比赛，主队控球后卫后撤步两分可惜不进\n",
      "欢迎收看湖人的比赛，客队小前锋三分命中\n",
      "欢迎观看湖人的比赛，客队小前锋三分命中\n",
      "欢迎收看湖人的比赛，客队控球后卫后仰跳投不进\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(generate_n(commentator, split='=',target='commentator'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**; 运行代码，观察是否能够生成多个句子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'D:/NLP/data/movie_comments.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = pd.read_csv(filename, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>中二得很</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                        link name  \\\n",
       "0  1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1  2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "2  3  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "3  4  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "4  5  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1  \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2  \n",
       "2  吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...    2  \n",
       "3                      凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。    4  \n",
       "4                                               中二得很    1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = content['comment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261497"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'吴京意淫到了脑残的地步，看了恶心想吐'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(string):\n",
    "    # we will learn the regular expression next course.\n",
    "    return re.findall('\\w+', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京意淫到了脑残的地步', '看了恶心想吐']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token(articles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['这个', '是', '用来', '做', '汉语言', '分词', '的']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "list(jieba.cut('这个是用来做汉语言分词的'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_jieba_cut = Counter(jieba.cut(articles[110]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('看过', 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_jieba_cut.most_common()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'没看过'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(token(articles[110]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_clean = [''.join(token(str(a)))for a in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261497"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'吴京的炒作水平不输冯小刚但小刚至少不会用主旋律来炒作吴京让人看了不舒服为了主旋律而主旋律为了煽情而煽情让人觉得他是个大做作大谎言家729更新片子整体不如湄公河行动1整体不够流畅编剧有毒台词尴尬2刻意做作的主旋律煽情显得如此不合时宜而又多余'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_clean[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movie_comment.txt', 'w',encoding='utf=8') as f:\n",
    "    for a in articles_clean:\n",
    "        f.write(a + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string): return jieba.cut(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TOKEN=cut(open('movie_comment.txt',encoding='utf8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n",
      "171000\n",
      "172000\n",
      "173000\n",
      "174000\n",
      "175000\n",
      "176000\n",
      "177000\n",
      "178000\n",
      "179000\n",
      "180000\n",
      "181000\n",
      "182000\n",
      "183000\n",
      "184000\n",
      "185000\n",
      "186000\n",
      "187000\n",
      "188000\n",
      "189000\n",
      "190000\n",
      "191000\n",
      "192000\n",
      "193000\n",
      "194000\n",
      "195000\n",
      "196000\n",
      "197000\n",
      "198000\n",
      "199000\n",
      "200000\n"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(ALL_TOKEN):\n",
    "    if i > 200000 : break\n",
    "    if i % 1000 == 0: print(i)\n",
    "    TOKEN.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200001"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = Counter(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 12392),\n",
       " ('\\n', 7812),\n",
       " ('了', 4729),\n",
       " ('是', 3006),\n",
       " ('我', 2124),\n",
       " ('都', 1695),\n",
       " ('和', 1416),\n",
       " ('在', 1343),\n",
       " ('也', 1313),\n",
       " ('看', 1269),\n",
       " ('不', 1207),\n",
       " ('电影', 1185),\n",
       " ('有', 1180),\n",
       " ('就', 1139),\n",
       " ('很', 1122),\n",
       " ('人', 1059),\n",
       " ('好', 903),\n",
       " ('你', 828),\n",
       " ('啊', 814),\n",
       " ('但', 747),\n",
       " ('这', 727),\n",
       " ('还', 724),\n",
       " ('一个', 701),\n",
       " ('还是', 684),\n",
       " ('让', 604),\n",
       " ('没有', 588),\n",
       " ('就是', 545),\n",
       " ('说', 527),\n",
       " ('剧情', 526),\n",
       " ('太', 525),\n",
       " ('故事', 509),\n",
       " ('他', 486),\n",
       " ('又', 486),\n",
       " ('上', 485),\n",
       " ('得', 485),\n",
       " ('给', 484),\n",
       " ('到', 480),\n",
       " ('没', 472),\n",
       " ('一部', 466),\n",
       " ('对', 462),\n",
       " ('最后', 442),\n",
       " ('被', 436),\n",
       " ('能', 415),\n",
       " ('吧', 406),\n",
       " ('最', 404),\n",
       " ('这个', 402),\n",
       " ('多', 399),\n",
       " ('要', 392),\n",
       " ('真的', 384),\n",
       " ('拍', 379),\n",
       " ('可以', 375),\n",
       " ('喜欢', 373),\n",
       " ('什么', 372),\n",
       " ('不是', 363),\n",
       " ('不错', 363),\n",
       " ('觉得', 357),\n",
       " ('与', 343),\n",
       " ('感觉', 332),\n",
       " ('演技', 329),\n",
       " ('好看', 327),\n",
       " ('去', 323),\n",
       " ('把', 321),\n",
       " ('动作', 319),\n",
       " ('导演', 315),\n",
       " ('里', 312),\n",
       " ('戏', 312),\n",
       " ('这么', 310),\n",
       " ('想', 309),\n",
       " ('自己', 308),\n",
       " ('着', 303),\n",
       " ('会', 293),\n",
       " ('片', 292),\n",
       " ('这部', 291),\n",
       " ('更', 291),\n",
       " ('片子', 288),\n",
       " ('打', 288),\n",
       " ('但是', 284),\n",
       " ('那么', 279),\n",
       " ('中', 276),\n",
       " ('那', 273),\n",
       " ('大', 270),\n",
       " ('吗', 266),\n",
       " ('有点', 261),\n",
       " ('来', 260),\n",
       " ('比', 256),\n",
       " ('个', 254),\n",
       " ('小', 253),\n",
       " ('这种', 252),\n",
       " ('知道', 252),\n",
       " ('真是', 249),\n",
       " ('这样', 246),\n",
       " ('演员', 244),\n",
       " ('而', 240),\n",
       " ('非常', 235),\n",
       " ('看到', 233),\n",
       " ('虽然', 232),\n",
       " ('我们', 230),\n",
       " ('再', 230),\n",
       " ('死', 230),\n",
       " ('像', 229)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequiences = [f for w, f in words_count.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f2b9b585c8>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, frequiences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count['我们']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_1(word):\n",
    "    return words_count[word] / len(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011499942500287498"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_1('我们')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京', '意淫', '到', '了', '脑残', '的', '地步', '看', '了', '恶心']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = [str(t) for t in TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_2_GRAM = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京意淫', '意淫到', '到了', '了脑残', '脑残的', '的地步', '地步看', '看了', '了恶心', '恶心想']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN_2_GRAM[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count_2 = Counter(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_1(word): return words_count[word] / len(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2(word1, word2):\n",
    "    if word1 + word2 in words_count_2: \n",
    "        return words_count_2[word1+word2] / words_count[word2]\n",
    "    else:\n",
    "        return 1 / len(words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007446016381236039"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('我们', '在')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability(sentence):\n",
    "    words = list(cut(sentence))\n",
    "    \n",
    "    sentence_pro = 1\n",
    "    \n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        next_ = words[i+1]\n",
    "        \n",
    "        probability = prob_2(word, next_)\n",
    "        \n",
    "        sentence_pro *= probability\n",
    "    \n",
    "    sentence_pro *= prob_1(words[-1])\n",
    "    \n",
    "    return sentence_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.015940899764775e-31"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probability('小明今天抽奖抽到一台苹果手机')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0277232370431489e-30"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probability('小明今天抽奖抽到一架波音飞机')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probability('洋葱奶昔来一杯')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明天晚上请你吃大餐，我们一起吃苹果 is more possible\n",
      "---- 今天晚上请你吃大餐，我们一起吃日料 with probility 0.0\n",
      "---- 明天晚上请你吃大餐，我们一起吃苹果 with probility 3.4834611559372426e-39\n",
      "真是一只好看的小猫 is more possible\n",
      "---- 真事一只好看的小猫 with probility 0.0\n",
      "---- 真是一只好看的小猫 with probility 0.0\n",
      "今晚火锅去吃我 is more possible\n",
      "---- 今晚我去吃火锅 with probility 0.0\n",
      "---- 今晚火锅去吃我 with probility 3.540218572645702e-19\n",
      "养乐多绿来一杯 is more possible\n",
      "---- 洋葱奶昔来一杯 with probility 0.0\n",
      "---- 养乐多绿来一杯 with probility 0.0\n"
     ]
    }
   ],
   "source": [
    "need_compared = [\n",
    "    \"今天晚上请你吃大餐，我们一起吃日料 明天晚上请你吃大餐，我们一起吃苹果\",\n",
    "    \"真事一只好看的小猫 真是一只好看的小猫\",\n",
    "    \"今晚我去吃火锅 今晚火锅去吃我\",\n",
    "    \"洋葱奶昔来一杯 养乐多绿来一杯\"\n",
    "]\n",
    "\n",
    "for s in need_compared:\n",
    "    s1, s2 = s.split()\n",
    "    p1, p2 = get_probability(s1), get_probability(s2)\n",
    "    \n",
    "    better = s1 if p1 > p2 else s2\n",
    "    \n",
    "    print('{} is more possible'.format(better))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s1, p1))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s2, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点** 1. 是否使用了新的数据集； 2. csv(txt)数据是否正确解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0), (1, 4), (4, 4), (2, 5)]"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 4), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(grammar_str,split,target):\n",
    "    lists=[]\n",
    "    for i in range(10):\n",
    "        s = generate_by_str(grammar_str,split,target)\n",
    "        p = get_probability(s)\n",
    "        list=[s,p]\n",
    "        lists.append(list)\n",
    "        lists=sorted(lists,key=lambda x: x[1],reverse=True)\n",
    "    return lists[0]\n",
    "  \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['欢迎观看凯尔特人的比赛，客队控球后卫上篮不进', 1.6134736510617184e-46]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(commentator, split='=',target='commentator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(): # you code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**： 是否使用 lambda 语法进行排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:movie_comments里的字词有限，如果输入的字词不在这个字词库里，计算的概率就没有意义，所以说数据量还是越大越好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**评阅点**: 是否提出了比较实际的问题，例如OOV问题，例如数据量，例如变成 3-gram问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
